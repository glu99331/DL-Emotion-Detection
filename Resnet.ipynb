{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC6lBRgpDROB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import pickle\n",
        "from PIL import *\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.applications import DenseNet121 # 2017 architecture\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.utils import plot_model\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from keras import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers, optimizers\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZTCI9JfDUl6",
        "outputId": "67e02bf3-6488-461a-cebc-81e5bd62ca7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "facialexpression_df = pd.read_csv('/content/drive/MyDrive/DL Facial Recognition/icml_face_data.csv')\n",
        "facialexpression_df = facialexpression_df.drop(columns=\" Usage\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKA1D93xhGVA"
      },
      "outputs": [],
      "source": [
        "def conv_block(X, f, filters, stage, block, strides=(2, 2), weight_decay=1e-3):\n",
        "    F1, F2, F3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Save the input value for shortcut\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(F1, (1, 1), strides=strides, padding='valid', name=conv_name_base + '2a',\n",
        "               kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(weight_decay))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component\n",
        "    X = Conv2D(F2, (f, f), padding='same', name=conv_name_base + '2b',\n",
        "               kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(weight_decay))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component\n",
        "    X = Conv2D(F3, (1, 1), padding='valid', name=conv_name_base + '2c',\n",
        "               kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(weight_decay))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    # Shortcut path\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides=strides, padding='valid', name=conv_name_base + '1',\n",
        "                        kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(weight_decay))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\"\"\"\n",
        "    F1, F2, F3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(F1, (1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component\n",
        "    X = Conv2D(F2, (f, f), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component\n",
        "    X = Conv2D(F3, (1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    # Add shortcut\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def apply_blocks(X, filter_triplets, first_strides, num_identity_blocks, stage):\n",
        "    \"\"\"Apply a convolutional block followed by multiple identity blocks.\"\"\"\n",
        "    # Apply the first convolutional block with stride changes\n",
        "    X = conv_block(X, 3, filter_triplets, stage, 'a', strides=first_strides)\n",
        "    # Apply subsequent identity blocks\n",
        "    for i in range(num_identity_blocks):\n",
        "        X = identity_block(X, 3, filter_triplets, stage, chr(98 + i))  # 'b', 'c', etc.\n",
        "    return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRHsWwaUDYS4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define function to convert string to array\n",
        "def string2array(x):\n",
        "    return np.array(x.split(' ')).reshape(48, 48, 1).astype('float32')\n",
        "# Define function to resize images\n",
        "def resize(x):\n",
        "    img = x.reshape(48, 48)\n",
        "    return cv2.resize(img, dsize=(96, 96), interpolation=cv2.INTER_CUBIC)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMDUaxxYDiOz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Apply preprocessing to pixels column\n",
        "facialexpression_df[' pixels'] = facialexpression_df[' pixels'].apply(lambda x: string2array(x))\n",
        "facialexpression_df[' pixels'] =  facialexpression_df[' pixels'].apply(lambda x : resize(x))\n",
        "# Define emotions of interest\n",
        "emotions = [1]  # Example: you want to work with emotion label 1\n",
        "label_to_text = {0: 'anger', 1 : 'disgust', 2 : 'fear', 3 : 'happiness', 4: 'sad', 5: 'surprise', 6: 'neutral'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "QLO4x235Dknm",
        "outputId": "ee71a88f-2cfa-4f76-95b4-cc3e7be93cb7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot sample images\n",
        "for i in emotions:\n",
        "    data = facialexpression_df[facialexpression_df['emotion'] == i][:1]\n",
        "    img = data[' pixels'].item()\n",
        "    img = img.reshape(96, 96)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(label_to_text[i])\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9HQ-2-fDlQx"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Prepare input and target data\n",
        "X = facialexpression_df[' pixels']\n",
        "y = to_categorical(facialexpression_df['emotion'])\n",
        "\n",
        "X = np.stack(X, axis = 0)\n",
        "X = X.reshape(35887,96,96,1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True)\n",
        "\n",
        "X_train = X_train/255\n",
        "X_val   = X_val /255\n",
        "X_test  = X_test/255\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "rotation_range = 15,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = \"nearest\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zbtGURQDvWC",
        "outputId": "61637463-4023-4452-f499-232702d89f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"CustomResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 96, 96, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " zero_padding2d_4 (ZeroPadd  (None, 102, 102, 1)          0         ['input_5[0][0]']             \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)              (None, 48, 48, 64)           3200      ['zero_padding2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " bn_conv1 (BatchNormalizati  (None, 48, 48, 64)           256       ['conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 48, 48, 64)           0         ['bn_conv1[0][0]']            \n",
            "                                                                                                  \n",
            " activation_196 (Activation  (None, 48, 48, 64)           0         ['dropout_4[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 24, 24, 64)           0         ['activation_196[0][0]']      \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " res2a_branch2a (Conv2D)     (None, 24, 24, 64)           4160      ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " bn2a_branch2a (BatchNormal  (None, 24, 24, 64)           256       ['res2a_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_197 (Activation  (None, 24, 24, 64)           0         ['bn2a_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2a_branch2b (Conv2D)     (None, 24, 24, 64)           36928     ['activation_197[0][0]']      \n",
            "                                                                                                  \n",
            " bn2a_branch2b (BatchNormal  (None, 24, 24, 64)           256       ['res2a_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_198 (Activation  (None, 24, 24, 64)           0         ['bn2a_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2a_branch2c (Conv2D)     (None, 24, 24, 256)          16640     ['activation_198[0][0]']      \n",
            "                                                                                                  \n",
            " res2a_branch1 (Conv2D)      (None, 24, 24, 256)          16640     ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " bn2a_branch2c (BatchNormal  (None, 24, 24, 256)          1024      ['res2a_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " bn2a_branch1 (BatchNormali  (None, 24, 24, 256)          1024      ['res2a_branch1[0][0]']       \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " add_64 (Add)                (None, 24, 24, 256)          0         ['bn2a_branch2c[0][0]',       \n",
            "                                                                     'bn2a_branch1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_199 (Activation  (None, 24, 24, 256)          0         ['add_64[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2b_branch2a (Conv2D)     (None, 24, 24, 64)           16448     ['activation_199[0][0]']      \n",
            "                                                                                                  \n",
            " bn2b_branch2a (BatchNormal  (None, 24, 24, 64)           256       ['res2b_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_200 (Activation  (None, 24, 24, 64)           0         ['bn2b_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2b_branch2b (Conv2D)     (None, 24, 24, 64)           36928     ['activation_200[0][0]']      \n",
            "                                                                                                  \n",
            " bn2b_branch2b (BatchNormal  (None, 24, 24, 64)           256       ['res2b_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_201 (Activation  (None, 24, 24, 64)           0         ['bn2b_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2b_branch2c (Conv2D)     (None, 24, 24, 256)          16640     ['activation_201[0][0]']      \n",
            "                                                                                                  \n",
            " bn2b_branch2c (BatchNormal  (None, 24, 24, 256)          1024      ['res2b_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_65 (Add)                (None, 24, 24, 256)          0         ['bn2b_branch2c[0][0]',       \n",
            "                                                                     'activation_199[0][0]']      \n",
            "                                                                                                  \n",
            " activation_202 (Activation  (None, 24, 24, 256)          0         ['add_65[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2c_branch2a (Conv2D)     (None, 24, 24, 64)           16448     ['activation_202[0][0]']      \n",
            "                                                                                                  \n",
            " bn2c_branch2a (BatchNormal  (None, 24, 24, 64)           256       ['res2c_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_203 (Activation  (None, 24, 24, 64)           0         ['bn2c_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2c_branch2b (Conv2D)     (None, 24, 24, 64)           36928     ['activation_203[0][0]']      \n",
            "                                                                                                  \n",
            " bn2c_branch2b (BatchNormal  (None, 24, 24, 64)           256       ['res2c_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_204 (Activation  (None, 24, 24, 64)           0         ['bn2c_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2c_branch2c (Conv2D)     (None, 24, 24, 256)          16640     ['activation_204[0][0]']      \n",
            "                                                                                                  \n",
            " bn2c_branch2c (BatchNormal  (None, 24, 24, 256)          1024      ['res2c_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_66 (Add)                (None, 24, 24, 256)          0         ['bn2c_branch2c[0][0]',       \n",
            "                                                                     'activation_202[0][0]']      \n",
            "                                                                                                  \n",
            " activation_205 (Activation  (None, 24, 24, 256)          0         ['add_66[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3a_branch2a (Conv2D)     (None, 12, 12, 128)          32896     ['activation_205[0][0]']      \n",
            "                                                                                                  \n",
            " bn3a_branch2a (BatchNormal  (None, 12, 12, 128)          512       ['res3a_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_206 (Activation  (None, 12, 12, 128)          0         ['bn3a_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3a_branch2b (Conv2D)     (None, 12, 12, 128)          147584    ['activation_206[0][0]']      \n",
            "                                                                                                  \n",
            " bn3a_branch2b (BatchNormal  (None, 12, 12, 128)          512       ['res3a_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_207 (Activation  (None, 12, 12, 128)          0         ['bn3a_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3a_branch2c (Conv2D)     (None, 12, 12, 512)          66048     ['activation_207[0][0]']      \n",
            "                                                                                                  \n",
            " res3a_branch1 (Conv2D)      (None, 12, 12, 512)          131584    ['activation_205[0][0]']      \n",
            "                                                                                                  \n",
            " bn3a_branch2c (BatchNormal  (None, 12, 12, 512)          2048      ['res3a_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " bn3a_branch1 (BatchNormali  (None, 12, 12, 512)          2048      ['res3a_branch1[0][0]']       \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " add_67 (Add)                (None, 12, 12, 512)          0         ['bn3a_branch2c[0][0]',       \n",
            "                                                                     'bn3a_branch1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_208 (Activation  (None, 12, 12, 512)          0         ['add_67[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3b_branch2a (Conv2D)     (None, 12, 12, 128)          65664     ['activation_208[0][0]']      \n",
            "                                                                                                  \n",
            " bn3b_branch2a (BatchNormal  (None, 12, 12, 128)          512       ['res3b_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_209 (Activation  (None, 12, 12, 128)          0         ['bn3b_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3b_branch2b (Conv2D)     (None, 12, 12, 128)          147584    ['activation_209[0][0]']      \n",
            "                                                                                                  \n",
            " bn3b_branch2b (BatchNormal  (None, 12, 12, 128)          512       ['res3b_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_210 (Activation  (None, 12, 12, 128)          0         ['bn3b_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3b_branch2c (Conv2D)     (None, 12, 12, 512)          66048     ['activation_210[0][0]']      \n",
            "                                                                                                  \n",
            " bn3b_branch2c (BatchNormal  (None, 12, 12, 512)          2048      ['res3b_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_68 (Add)                (None, 12, 12, 512)          0         ['bn3b_branch2c[0][0]',       \n",
            "                                                                     'activation_208[0][0]']      \n",
            "                                                                                                  \n",
            " activation_211 (Activation  (None, 12, 12, 512)          0         ['add_68[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3c_branch2a (Conv2D)     (None, 12, 12, 128)          65664     ['activation_211[0][0]']      \n",
            "                                                                                                  \n",
            " bn3c_branch2a (BatchNormal  (None, 12, 12, 128)          512       ['res3c_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_212 (Activation  (None, 12, 12, 128)          0         ['bn3c_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3c_branch2b (Conv2D)     (None, 12, 12, 128)          147584    ['activation_212[0][0]']      \n",
            "                                                                                                  \n",
            " bn3c_branch2b (BatchNormal  (None, 12, 12, 128)          512       ['res3c_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_213 (Activation  (None, 12, 12, 128)          0         ['bn3c_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3c_branch2c (Conv2D)     (None, 12, 12, 512)          66048     ['activation_213[0][0]']      \n",
            "                                                                                                  \n",
            " bn3c_branch2c (BatchNormal  (None, 12, 12, 512)          2048      ['res3c_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_69 (Add)                (None, 12, 12, 512)          0         ['bn3c_branch2c[0][0]',       \n",
            "                                                                     'activation_211[0][0]']      \n",
            "                                                                                                  \n",
            " activation_214 (Activation  (None, 12, 12, 512)          0         ['add_69[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3d_branch2a (Conv2D)     (None, 12, 12, 128)          65664     ['activation_214[0][0]']      \n",
            "                                                                                                  \n",
            " bn3d_branch2a (BatchNormal  (None, 12, 12, 128)          512       ['res3d_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_215 (Activation  (None, 12, 12, 128)          0         ['bn3d_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3d_branch2b (Conv2D)     (None, 12, 12, 128)          147584    ['activation_215[0][0]']      \n",
            "                                                                                                  \n",
            " bn3d_branch2b (BatchNormal  (None, 12, 12, 128)          512       ['res3d_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_216 (Activation  (None, 12, 12, 128)          0         ['bn3d_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3d_branch2c (Conv2D)     (None, 12, 12, 512)          66048     ['activation_216[0][0]']      \n",
            "                                                                                                  \n",
            " bn3d_branch2c (BatchNormal  (None, 12, 12, 512)          2048      ['res3d_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_70 (Add)                (None, 12, 12, 512)          0         ['bn3d_branch2c[0][0]',       \n",
            "                                                                     'activation_214[0][0]']      \n",
            "                                                                                                  \n",
            " activation_217 (Activation  (None, 12, 12, 512)          0         ['add_70[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4a_branch2a (Conv2D)     (None, 6, 6, 256)            131328    ['activation_217[0][0]']      \n",
            "                                                                                                  \n",
            " bn4a_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4a_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_218 (Activation  (None, 6, 6, 256)            0         ['bn4a_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4a_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_218[0][0]']      \n",
            "                                                                                                  \n",
            " bn4a_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4a_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_219 (Activation  (None, 6, 6, 256)            0         ['bn4a_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4a_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_219[0][0]']      \n",
            "                                                                                                  \n",
            " res4a_branch1 (Conv2D)      (None, 6, 6, 1024)           525312    ['activation_217[0][0]']      \n",
            "                                                                                                  \n",
            " bn4a_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4a_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " bn4a_branch1 (BatchNormali  (None, 6, 6, 1024)           4096      ['res4a_branch1[0][0]']       \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " add_71 (Add)                (None, 6, 6, 1024)           0         ['bn4a_branch2c[0][0]',       \n",
            "                                                                     'bn4a_branch1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_220 (Activation  (None, 6, 6, 1024)           0         ['add_71[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4b_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_220[0][0]']      \n",
            "                                                                                                  \n",
            " bn4b_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4b_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_221 (Activation  (None, 6, 6, 256)            0         ['bn4b_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4b_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_221[0][0]']      \n",
            "                                                                                                  \n",
            " bn4b_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4b_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_222 (Activation  (None, 6, 6, 256)            0         ['bn4b_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4b_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_222[0][0]']      \n",
            "                                                                                                  \n",
            " bn4b_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4b_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_72 (Add)                (None, 6, 6, 1024)           0         ['bn4b_branch2c[0][0]',       \n",
            "                                                                     'activation_220[0][0]']      \n",
            "                                                                                                  \n",
            " activation_223 (Activation  (None, 6, 6, 1024)           0         ['add_72[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4c_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_223[0][0]']      \n",
            "                                                                                                  \n",
            " bn4c_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4c_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_224 (Activation  (None, 6, 6, 256)            0         ['bn4c_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4c_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_224[0][0]']      \n",
            "                                                                                                  \n",
            " bn4c_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4c_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_225 (Activation  (None, 6, 6, 256)            0         ['bn4c_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4c_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_225[0][0]']      \n",
            "                                                                                                  \n",
            " bn4c_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4c_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_73 (Add)                (None, 6, 6, 1024)           0         ['bn4c_branch2c[0][0]',       \n",
            "                                                                     'activation_223[0][0]']      \n",
            "                                                                                                  \n",
            " activation_226 (Activation  (None, 6, 6, 1024)           0         ['add_73[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4d_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_226[0][0]']      \n",
            "                                                                                                  \n",
            " bn4d_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4d_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_227 (Activation  (None, 6, 6, 256)            0         ['bn4d_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4d_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_227[0][0]']      \n",
            "                                                                                                  \n",
            " bn4d_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4d_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_228 (Activation  (None, 6, 6, 256)            0         ['bn4d_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4d_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_228[0][0]']      \n",
            "                                                                                                  \n",
            " bn4d_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4d_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_74 (Add)                (None, 6, 6, 1024)           0         ['bn4d_branch2c[0][0]',       \n",
            "                                                                     'activation_226[0][0]']      \n",
            "                                                                                                  \n",
            " activation_229 (Activation  (None, 6, 6, 1024)           0         ['add_74[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4e_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_229[0][0]']      \n",
            "                                                                                                  \n",
            " bn4e_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4e_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_230 (Activation  (None, 6, 6, 256)            0         ['bn4e_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4e_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_230[0][0]']      \n",
            "                                                                                                  \n",
            " bn4e_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4e_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_231 (Activation  (None, 6, 6, 256)            0         ['bn4e_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4e_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_231[0][0]']      \n",
            "                                                                                                  \n",
            " bn4e_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4e_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_75 (Add)                (None, 6, 6, 1024)           0         ['bn4e_branch2c[0][0]',       \n",
            "                                                                     'activation_229[0][0]']      \n",
            "                                                                                                  \n",
            " activation_232 (Activation  (None, 6, 6, 1024)           0         ['add_75[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4f_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_232[0][0]']      \n",
            "                                                                                                  \n",
            " bn4f_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4f_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_233 (Activation  (None, 6, 6, 256)            0         ['bn4f_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4f_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_233[0][0]']      \n",
            "                                                                                                  \n",
            " bn4f_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4f_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_234 (Activation  (None, 6, 6, 256)            0         ['bn4f_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4f_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_234[0][0]']      \n",
            "                                                                                                  \n",
            " bn4f_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4f_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_76 (Add)                (None, 6, 6, 1024)           0         ['bn4f_branch2c[0][0]',       \n",
            "                                                                     'activation_232[0][0]']      \n",
            "                                                                                                  \n",
            " activation_235 (Activation  (None, 6, 6, 1024)           0         ['add_76[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5a_branch2a (Conv2D)     (None, 3, 3, 512)            524800    ['activation_235[0][0]']      \n",
            "                                                                                                  \n",
            " bn5a_branch2a (BatchNormal  (None, 3, 3, 512)            2048      ['res5a_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_236 (Activation  (None, 3, 3, 512)            0         ['bn5a_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5a_branch2b (Conv2D)     (None, 3, 3, 512)            2359808   ['activation_236[0][0]']      \n",
            "                                                                                                  \n",
            " bn5a_branch2b (BatchNormal  (None, 3, 3, 512)            2048      ['res5a_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_237 (Activation  (None, 3, 3, 512)            0         ['bn5a_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5a_branch2c (Conv2D)     (None, 3, 3, 2048)           1050624   ['activation_237[0][0]']      \n",
            "                                                                                                  \n",
            " res5a_branch1 (Conv2D)      (None, 3, 3, 2048)           2099200   ['activation_235[0][0]']      \n",
            "                                                                                                  \n",
            " bn5a_branch2c (BatchNormal  (None, 3, 3, 2048)           8192      ['res5a_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " bn5a_branch1 (BatchNormali  (None, 3, 3, 2048)           8192      ['res5a_branch1[0][0]']       \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " add_77 (Add)                (None, 3, 3, 2048)           0         ['bn5a_branch2c[0][0]',       \n",
            "                                                                     'bn5a_branch1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_238 (Activation  (None, 3, 3, 2048)           0         ['add_77[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5b_branch2a (Conv2D)     (None, 3, 3, 512)            1049088   ['activation_238[0][0]']      \n",
            "                                                                                                  \n",
            " bn5b_branch2a (BatchNormal  (None, 3, 3, 512)            2048      ['res5b_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_239 (Activation  (None, 3, 3, 512)            0         ['bn5b_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5b_branch2b (Conv2D)     (None, 3, 3, 512)            2359808   ['activation_239[0][0]']      \n",
            "                                                                                                  \n",
            " bn5b_branch2b (BatchNormal  (None, 3, 3, 512)            2048      ['res5b_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_240 (Activation  (None, 3, 3, 512)            0         ['bn5b_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5b_branch2c (Conv2D)     (None, 3, 3, 2048)           1050624   ['activation_240[0][0]']      \n",
            "                                                                                                  \n",
            " bn5b_branch2c (BatchNormal  (None, 3, 3, 2048)           8192      ['res5b_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_78 (Add)                (None, 3, 3, 2048)           0         ['bn5b_branch2c[0][0]',       \n",
            "                                                                     'activation_238[0][0]']      \n",
            "                                                                                                  \n",
            " activation_241 (Activation  (None, 3, 3, 2048)           0         ['add_78[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5c_branch2a (Conv2D)     (None, 3, 3, 512)            1049088   ['activation_241[0][0]']      \n",
            "                                                                                                  \n",
            " bn5c_branch2a (BatchNormal  (None, 3, 3, 512)            2048      ['res5c_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_242 (Activation  (None, 3, 3, 512)            0         ['bn5c_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5c_branch2b (Conv2D)     (None, 3, 3, 512)            2359808   ['activation_242[0][0]']      \n",
            "                                                                                                  \n",
            " bn5c_branch2b (BatchNormal  (None, 3, 3, 512)            2048      ['res5c_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_243 (Activation  (None, 3, 3, 512)            0         ['bn5c_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5c_branch2c (Conv2D)     (None, 3, 3, 2048)           1050624   ['activation_243[0][0]']      \n",
            "                                                                                                  \n",
            " bn5c_branch2c (BatchNormal  (None, 3, 3, 2048)           8192      ['res5c_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_79 (Add)                (None, 3, 3, 2048)           0         ['bn5c_branch2c[0][0]',       \n",
            "                                                                     'activation_241[0][0]']      \n",
            "                                                                                                  \n",
            " activation_244 (Activation  (None, 3, 3, 2048)           0         ['add_79[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4  (None, 2048)                 0         ['activation_244[0][0]']      \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " final_output (Dense)        (None, 7)                    14343     ['global_average_pooling2d_4[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23595783 (90.01 MB)\n",
            "Trainable params: 23542663 (89.81 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the input tensor shape\n",
        "input_shape = (96, 96, 1)\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Initial convolution and max pooling\n",
        "X = ZeroPadding2D((3, 3))(X_input)\n",
        "X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "X = Dropout(0.5)(X)  # Add dropout\n",
        "X = Activation('relu')(X)\n",
        "X = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(X)\n",
        "\n",
        "# Helper function to apply a convolutional block and multiple identity blocks\n",
        "def apply_blocks(X, filter_triplets, first_strides, num_identity_blocks, stage):\n",
        "    # Apply convolutional block\n",
        "    X = conv_block(X, 3, filter_triplets, stage, 'a', strides=first_strides)\n",
        "    # Apply identity blocks\n",
        "    for i in range(num_identity_blocks):\n",
        "        X = identity_block(X, 3, filter_triplets, stage, chr(98 + i))  # 'b', 'c', ..., for identity blocks\n",
        "    return X\n",
        "\n",
        "# Stage 2\n",
        "X = apply_blocks(X, [64, 64, 256], (1, 1), 2, 2)\n",
        "\n",
        "# Stage 3\n",
        "X = apply_blocks(X, [128, 128, 512], (2, 2), 3, 3)\n",
        "\n",
        "# Stage 4\n",
        "X = apply_blocks(X, [256, 256, 1024], (2, 2), 5, 4)\n",
        "\n",
        "# Stage 5\n",
        "X = apply_blocks(X, [512, 512, 2048], (2, 2), 2, 5)\n",
        "\n",
        "# Global Average Pooling and final dense layer\n",
        "X = GlobalAveragePooling2D()(X)\n",
        "X = Dense(7, activation='softmax', name='final_output')(X)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=X_input, outputs=X, name='CustomResNet50')\n",
        "# Show the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gAe0Z91Dxqw",
        "outputId": "af8f0363-e5ec-4f7c-a8bd-df563e956ce7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"CustomResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 96, 96, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " zero_padding2d_4 (ZeroPadd  (None, 102, 102, 1)          0         ['input_5[0][0]']             \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)              (None, 48, 48, 64)           3200      ['zero_padding2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " bn_conv1 (BatchNormalizati  (None, 48, 48, 64)           256       ['conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 48, 48, 64)           0         ['bn_conv1[0][0]']            \n",
            "                                                                                                  \n",
            " activation_196 (Activation  (None, 48, 48, 64)           0         ['dropout_4[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 24, 24, 64)           0         ['activation_196[0][0]']      \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " res2a_branch2a (Conv2D)     (None, 24, 24, 64)           4160      ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " bn2a_branch2a (BatchNormal  (None, 24, 24, 64)           256       ['res2a_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_197 (Activation  (None, 24, 24, 64)           0         ['bn2a_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2a_branch2b (Conv2D)     (None, 24, 24, 64)           36928     ['activation_197[0][0]']      \n",
            "                                                                                                  \n",
            " bn2a_branch2b (BatchNormal  (None, 24, 24, 64)           256       ['res2a_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_198 (Activation  (None, 24, 24, 64)           0         ['bn2a_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2a_branch2c (Conv2D)     (None, 24, 24, 256)          16640     ['activation_198[0][0]']      \n",
            "                                                                                                  \n",
            " res2a_branch1 (Conv2D)      (None, 24, 24, 256)          16640     ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " bn2a_branch2c (BatchNormal  (None, 24, 24, 256)          1024      ['res2a_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " bn2a_branch1 (BatchNormali  (None, 24, 24, 256)          1024      ['res2a_branch1[0][0]']       \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " add_64 (Add)                (None, 24, 24, 256)          0         ['bn2a_branch2c[0][0]',       \n",
            "                                                                     'bn2a_branch1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_199 (Activation  (None, 24, 24, 256)          0         ['add_64[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2b_branch2a (Conv2D)     (None, 24, 24, 64)           16448     ['activation_199[0][0]']      \n",
            "                                                                                                  \n",
            " bn2b_branch2a (BatchNormal  (None, 24, 24, 64)           256       ['res2b_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_200 (Activation  (None, 24, 24, 64)           0         ['bn2b_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2b_branch2b (Conv2D)     (None, 24, 24, 64)           36928     ['activation_200[0][0]']      \n",
            "                                                                                                  \n",
            " bn2b_branch2b (BatchNormal  (None, 24, 24, 64)           256       ['res2b_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_201 (Activation  (None, 24, 24, 64)           0         ['bn2b_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2b_branch2c (Conv2D)     (None, 24, 24, 256)          16640     ['activation_201[0][0]']      \n",
            "                                                                                                  \n",
            " bn2b_branch2c (BatchNormal  (None, 24, 24, 256)          1024      ['res2b_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_65 (Add)                (None, 24, 24, 256)          0         ['bn2b_branch2c[0][0]',       \n",
            "                                                                     'activation_199[0][0]']      \n",
            "                                                                                                  \n",
            " activation_202 (Activation  (None, 24, 24, 256)          0         ['add_65[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2c_branch2a (Conv2D)     (None, 24, 24, 64)           16448     ['activation_202[0][0]']      \n",
            "                                                                                                  \n",
            " bn2c_branch2a (BatchNormal  (None, 24, 24, 64)           256       ['res2c_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_203 (Activation  (None, 24, 24, 64)           0         ['bn2c_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2c_branch2b (Conv2D)     (None, 24, 24, 64)           36928     ['activation_203[0][0]']      \n",
            "                                                                                                  \n",
            " bn2c_branch2b (BatchNormal  (None, 24, 24, 64)           256       ['res2c_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_204 (Activation  (None, 24, 24, 64)           0         ['bn2c_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res2c_branch2c (Conv2D)     (None, 24, 24, 256)          16640     ['activation_204[0][0]']      \n",
            "                                                                                                  \n",
            " bn2c_branch2c (BatchNormal  (None, 24, 24, 256)          1024      ['res2c_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_66 (Add)                (None, 24, 24, 256)          0         ['bn2c_branch2c[0][0]',       \n",
            "                                                                     'activation_202[0][0]']      \n",
            "                                                                                                  \n",
            " activation_205 (Activation  (None, 24, 24, 256)          0         ['add_66[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3a_branch2a (Conv2D)     (None, 12, 12, 128)          32896     ['activation_205[0][0]']      \n",
            "                                                                                                  \n",
            " bn3a_branch2a (BatchNormal  (None, 12, 12, 128)          512       ['res3a_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_206 (Activation  (None, 12, 12, 128)          0         ['bn3a_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3a_branch2b (Conv2D)     (None, 12, 12, 128)          147584    ['activation_206[0][0]']      \n",
            "                                                                                                  \n",
            " bn3a_branch2b (BatchNormal  (None, 12, 12, 128)          512       ['res3a_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_207 (Activation  (None, 12, 12, 128)          0         ['bn3a_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3a_branch2c (Conv2D)     (None, 12, 12, 512)          66048     ['activation_207[0][0]']      \n",
            "                                                                                                  \n",
            " res3a_branch1 (Conv2D)      (None, 12, 12, 512)          131584    ['activation_205[0][0]']      \n",
            "                                                                                                  \n",
            " bn3a_branch2c (BatchNormal  (None, 12, 12, 512)          2048      ['res3a_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " bn3a_branch1 (BatchNormali  (None, 12, 12, 512)          2048      ['res3a_branch1[0][0]']       \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " add_67 (Add)                (None, 12, 12, 512)          0         ['bn3a_branch2c[0][0]',       \n",
            "                                                                     'bn3a_branch1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_208 (Activation  (None, 12, 12, 512)          0         ['add_67[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3b_branch2a (Conv2D)     (None, 12, 12, 128)          65664     ['activation_208[0][0]']      \n",
            "                                                                                                  \n",
            " bn3b_branch2a (BatchNormal  (None, 12, 12, 128)          512       ['res3b_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_209 (Activation  (None, 12, 12, 128)          0         ['bn3b_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3b_branch2b (Conv2D)     (None, 12, 12, 128)          147584    ['activation_209[0][0]']      \n",
            "                                                                                                  \n",
            " bn3b_branch2b (BatchNormal  (None, 12, 12, 128)          512       ['res3b_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_210 (Activation  (None, 12, 12, 128)          0         ['bn3b_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3b_branch2c (Conv2D)     (None, 12, 12, 512)          66048     ['activation_210[0][0]']      \n",
            "                                                                                                  \n",
            " bn3b_branch2c (BatchNormal  (None, 12, 12, 512)          2048      ['res3b_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_68 (Add)                (None, 12, 12, 512)          0         ['bn3b_branch2c[0][0]',       \n",
            "                                                                     'activation_208[0][0]']      \n",
            "                                                                                                  \n",
            " activation_211 (Activation  (None, 12, 12, 512)          0         ['add_68[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3c_branch2a (Conv2D)     (None, 12, 12, 128)          65664     ['activation_211[0][0]']      \n",
            "                                                                                                  \n",
            " bn3c_branch2a (BatchNormal  (None, 12, 12, 128)          512       ['res3c_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_212 (Activation  (None, 12, 12, 128)          0         ['bn3c_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3c_branch2b (Conv2D)     (None, 12, 12, 128)          147584    ['activation_212[0][0]']      \n",
            "                                                                                                  \n",
            " bn3c_branch2b (BatchNormal  (None, 12, 12, 128)          512       ['res3c_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_213 (Activation  (None, 12, 12, 128)          0         ['bn3c_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3c_branch2c (Conv2D)     (None, 12, 12, 512)          66048     ['activation_213[0][0]']      \n",
            "                                                                                                  \n",
            " bn3c_branch2c (BatchNormal  (None, 12, 12, 512)          2048      ['res3c_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_69 (Add)                (None, 12, 12, 512)          0         ['bn3c_branch2c[0][0]',       \n",
            "                                                                     'activation_211[0][0]']      \n",
            "                                                                                                  \n",
            " activation_214 (Activation  (None, 12, 12, 512)          0         ['add_69[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3d_branch2a (Conv2D)     (None, 12, 12, 128)          65664     ['activation_214[0][0]']      \n",
            "                                                                                                  \n",
            " bn3d_branch2a (BatchNormal  (None, 12, 12, 128)          512       ['res3d_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_215 (Activation  (None, 12, 12, 128)          0         ['bn3d_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3d_branch2b (Conv2D)     (None, 12, 12, 128)          147584    ['activation_215[0][0]']      \n",
            "                                                                                                  \n",
            " bn3d_branch2b (BatchNormal  (None, 12, 12, 128)          512       ['res3d_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_216 (Activation  (None, 12, 12, 128)          0         ['bn3d_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res3d_branch2c (Conv2D)     (None, 12, 12, 512)          66048     ['activation_216[0][0]']      \n",
            "                                                                                                  \n",
            " bn3d_branch2c (BatchNormal  (None, 12, 12, 512)          2048      ['res3d_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_70 (Add)                (None, 12, 12, 512)          0         ['bn3d_branch2c[0][0]',       \n",
            "                                                                     'activation_214[0][0]']      \n",
            "                                                                                                  \n",
            " activation_217 (Activation  (None, 12, 12, 512)          0         ['add_70[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4a_branch2a (Conv2D)     (None, 6, 6, 256)            131328    ['activation_217[0][0]']      \n",
            "                                                                                                  \n",
            " bn4a_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4a_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_218 (Activation  (None, 6, 6, 256)            0         ['bn4a_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4a_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_218[0][0]']      \n",
            "                                                                                                  \n",
            " bn4a_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4a_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_219 (Activation  (None, 6, 6, 256)            0         ['bn4a_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4a_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_219[0][0]']      \n",
            "                                                                                                  \n",
            " res4a_branch1 (Conv2D)      (None, 6, 6, 1024)           525312    ['activation_217[0][0]']      \n",
            "                                                                                                  \n",
            " bn4a_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4a_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " bn4a_branch1 (BatchNormali  (None, 6, 6, 1024)           4096      ['res4a_branch1[0][0]']       \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " add_71 (Add)                (None, 6, 6, 1024)           0         ['bn4a_branch2c[0][0]',       \n",
            "                                                                     'bn4a_branch1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_220 (Activation  (None, 6, 6, 1024)           0         ['add_71[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4b_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_220[0][0]']      \n",
            "                                                                                                  \n",
            " bn4b_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4b_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_221 (Activation  (None, 6, 6, 256)            0         ['bn4b_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4b_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_221[0][0]']      \n",
            "                                                                                                  \n",
            " bn4b_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4b_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_222 (Activation  (None, 6, 6, 256)            0         ['bn4b_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4b_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_222[0][0]']      \n",
            "                                                                                                  \n",
            " bn4b_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4b_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_72 (Add)                (None, 6, 6, 1024)           0         ['bn4b_branch2c[0][0]',       \n",
            "                                                                     'activation_220[0][0]']      \n",
            "                                                                                                  \n",
            " activation_223 (Activation  (None, 6, 6, 1024)           0         ['add_72[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4c_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_223[0][0]']      \n",
            "                                                                                                  \n",
            " bn4c_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4c_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_224 (Activation  (None, 6, 6, 256)            0         ['bn4c_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4c_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_224[0][0]']      \n",
            "                                                                                                  \n",
            " bn4c_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4c_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_225 (Activation  (None, 6, 6, 256)            0         ['bn4c_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4c_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_225[0][0]']      \n",
            "                                                                                                  \n",
            " bn4c_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4c_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_73 (Add)                (None, 6, 6, 1024)           0         ['bn4c_branch2c[0][0]',       \n",
            "                                                                     'activation_223[0][0]']      \n",
            "                                                                                                  \n",
            " activation_226 (Activation  (None, 6, 6, 1024)           0         ['add_73[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4d_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_226[0][0]']      \n",
            "                                                                                                  \n",
            " bn4d_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4d_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_227 (Activation  (None, 6, 6, 256)            0         ['bn4d_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4d_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_227[0][0]']      \n",
            "                                                                                                  \n",
            " bn4d_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4d_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_228 (Activation  (None, 6, 6, 256)            0         ['bn4d_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4d_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_228[0][0]']      \n",
            "                                                                                                  \n",
            " bn4d_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4d_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_74 (Add)                (None, 6, 6, 1024)           0         ['bn4d_branch2c[0][0]',       \n",
            "                                                                     'activation_226[0][0]']      \n",
            "                                                                                                  \n",
            " activation_229 (Activation  (None, 6, 6, 1024)           0         ['add_74[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4e_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_229[0][0]']      \n",
            "                                                                                                  \n",
            " bn4e_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4e_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_230 (Activation  (None, 6, 6, 256)            0         ['bn4e_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4e_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_230[0][0]']      \n",
            "                                                                                                  \n",
            " bn4e_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4e_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_231 (Activation  (None, 6, 6, 256)            0         ['bn4e_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4e_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_231[0][0]']      \n",
            "                                                                                                  \n",
            " bn4e_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4e_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_75 (Add)                (None, 6, 6, 1024)           0         ['bn4e_branch2c[0][0]',       \n",
            "                                                                     'activation_229[0][0]']      \n",
            "                                                                                                  \n",
            " activation_232 (Activation  (None, 6, 6, 1024)           0         ['add_75[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4f_branch2a (Conv2D)     (None, 6, 6, 256)            262400    ['activation_232[0][0]']      \n",
            "                                                                                                  \n",
            " bn4f_branch2a (BatchNormal  (None, 6, 6, 256)            1024      ['res4f_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_233 (Activation  (None, 6, 6, 256)            0         ['bn4f_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4f_branch2b (Conv2D)     (None, 6, 6, 256)            590080    ['activation_233[0][0]']      \n",
            "                                                                                                  \n",
            " bn4f_branch2b (BatchNormal  (None, 6, 6, 256)            1024      ['res4f_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_234 (Activation  (None, 6, 6, 256)            0         ['bn4f_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res4f_branch2c (Conv2D)     (None, 6, 6, 1024)           263168    ['activation_234[0][0]']      \n",
            "                                                                                                  \n",
            " bn4f_branch2c (BatchNormal  (None, 6, 6, 1024)           4096      ['res4f_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_76 (Add)                (None, 6, 6, 1024)           0         ['bn4f_branch2c[0][0]',       \n",
            "                                                                     'activation_232[0][0]']      \n",
            "                                                                                                  \n",
            " activation_235 (Activation  (None, 6, 6, 1024)           0         ['add_76[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5a_branch2a (Conv2D)     (None, 3, 3, 512)            524800    ['activation_235[0][0]']      \n",
            "                                                                                                  \n",
            " bn5a_branch2a (BatchNormal  (None, 3, 3, 512)            2048      ['res5a_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_236 (Activation  (None, 3, 3, 512)            0         ['bn5a_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5a_branch2b (Conv2D)     (None, 3, 3, 512)            2359808   ['activation_236[0][0]']      \n",
            "                                                                                                  \n",
            " bn5a_branch2b (BatchNormal  (None, 3, 3, 512)            2048      ['res5a_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_237 (Activation  (None, 3, 3, 512)            0         ['bn5a_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5a_branch2c (Conv2D)     (None, 3, 3, 2048)           1050624   ['activation_237[0][0]']      \n",
            "                                                                                                  \n",
            " res5a_branch1 (Conv2D)      (None, 3, 3, 2048)           2099200   ['activation_235[0][0]']      \n",
            "                                                                                                  \n",
            " bn5a_branch2c (BatchNormal  (None, 3, 3, 2048)           8192      ['res5a_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " bn5a_branch1 (BatchNormali  (None, 3, 3, 2048)           8192      ['res5a_branch1[0][0]']       \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " add_77 (Add)                (None, 3, 3, 2048)           0         ['bn5a_branch2c[0][0]',       \n",
            "                                                                     'bn5a_branch1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_238 (Activation  (None, 3, 3, 2048)           0         ['add_77[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5b_branch2a (Conv2D)     (None, 3, 3, 512)            1049088   ['activation_238[0][0]']      \n",
            "                                                                                                  \n",
            " bn5b_branch2a (BatchNormal  (None, 3, 3, 512)            2048      ['res5b_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_239 (Activation  (None, 3, 3, 512)            0         ['bn5b_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5b_branch2b (Conv2D)     (None, 3, 3, 512)            2359808   ['activation_239[0][0]']      \n",
            "                                                                                                  \n",
            " bn5b_branch2b (BatchNormal  (None, 3, 3, 512)            2048      ['res5b_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_240 (Activation  (None, 3, 3, 512)            0         ['bn5b_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5b_branch2c (Conv2D)     (None, 3, 3, 2048)           1050624   ['activation_240[0][0]']      \n",
            "                                                                                                  \n",
            " bn5b_branch2c (BatchNormal  (None, 3, 3, 2048)           8192      ['res5b_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_78 (Add)                (None, 3, 3, 2048)           0         ['bn5b_branch2c[0][0]',       \n",
            "                                                                     'activation_238[0][0]']      \n",
            "                                                                                                  \n",
            " activation_241 (Activation  (None, 3, 3, 2048)           0         ['add_78[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5c_branch2a (Conv2D)     (None, 3, 3, 512)            1049088   ['activation_241[0][0]']      \n",
            "                                                                                                  \n",
            " bn5c_branch2a (BatchNormal  (None, 3, 3, 512)            2048      ['res5c_branch2a[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_242 (Activation  (None, 3, 3, 512)            0         ['bn5c_branch2a[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5c_branch2b (Conv2D)     (None, 3, 3, 512)            2359808   ['activation_242[0][0]']      \n",
            "                                                                                                  \n",
            " bn5c_branch2b (BatchNormal  (None, 3, 3, 512)            2048      ['res5c_branch2b[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_243 (Activation  (None, 3, 3, 512)            0         ['bn5c_branch2b[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " res5c_branch2c (Conv2D)     (None, 3, 3, 2048)           1050624   ['activation_243[0][0]']      \n",
            "                                                                                                  \n",
            " bn5c_branch2c (BatchNormal  (None, 3, 3, 2048)           8192      ['res5c_branch2c[0][0]']      \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_79 (Add)                (None, 3, 3, 2048)           0         ['bn5c_branch2c[0][0]',       \n",
            "                                                                     'activation_241[0][0]']      \n",
            "                                                                                                  \n",
            " activation_244 (Activation  (None, 3, 3, 2048)           0         ['add_79[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4  (None, 2048)                 0         ['activation_244[0][0]']      \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " final_output (Dense)        (None, 7)                    14343     ['global_average_pooling2d_4[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23595783 (90.01 MB)\n",
            "Trainable params: 23542663 (89.81 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the total number of epochs and the number of warmup epochs\n",
        "# Define the total number of epochs, the number of warmup epochs, and the batch size\n",
        "total_epochs = 100\n",
        "warmup_epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "# Define the initial learning rate and minimum learning rate\n",
        "initial_learning_rate = 1e-3\n",
        "min_learning_rate = 1e-6\n",
        "\n",
        "# Calculate the total number of steps and warmup steps\n",
        "total_steps = total_epochs * (len(X_train) // batch_size)\n",
        "warmup_steps = warmup_epochs * (len(X_train) // batch_size)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=1e-6)\n",
        "\n",
        "# Define the learning rate scheduler with warmup\n",
        "# Create the learning rate scheduler with warmup\n",
        "# def lr_schedule(epoch, lr):\n",
        "#     if epoch < warmup_epochs:\n",
        "#         # Linear warmup\n",
        "#         return initial_learning_rate * (epoch + 1) / warmup_epochs\n",
        "#     else:\n",
        "#         # Cosine annealing with restarts\n",
        "#         cosine_decay = 0.5 * (1 + tf.cos(tf.constant(np.pi) * (epoch - warmup_epochs) / (total_epochs - warmup_epochs)))\n",
        "#         decayed = (initial_learning_rate - min_learning_rate) * cosine_decay + min_learning_rate\n",
        "#         return decayed\n",
        "# using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
        "\n",
        "# save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath = \"/content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\", verbose = 1, save_best_only=True)\n",
        "# Compile the model\n",
        "model.compile(keras.optimizers.Adam(lr = 1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXvmFp_-XhIu",
        "outputId": "f5701f56-9127-4706-8138-a6f0ff56dd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.9022 - accuracy: 0.6823\n",
            "Epoch 1: val_loss improved from inf to 1.24784, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "504/504 [==============================] - 70s 86ms/step - loss: 0.9022 - accuracy: 0.6823 - val_loss: 1.2478 - val_accuracy: 0.5530 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8990 - accuracy: 0.6810\n",
            "Epoch 2: val_loss improved from 1.24784 to 1.19534, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 49s 97ms/step - loss: 0.8990 - accuracy: 0.6810 - val_loss: 1.1953 - val_accuracy: 0.5686 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8911 - accuracy: 0.6845\n",
            "Epoch 3: val_loss improved from 1.19534 to 1.12435, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 43s 84ms/step - loss: 0.8911 - accuracy: 0.6845 - val_loss: 1.1244 - val_accuracy: 0.5959 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8869 - accuracy: 0.6840\n",
            "Epoch 4: val_loss improved from 1.12435 to 1.12391, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 43s 84ms/step - loss: 0.8869 - accuracy: 0.6840 - val_loss: 1.1239 - val_accuracy: 0.6054 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8788 - accuracy: 0.6856\n",
            "Epoch 5: val_loss did not improve from 1.12391\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8788 - accuracy: 0.6856 - val_loss: 1.1605 - val_accuracy: 0.5886 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8818 - accuracy: 0.6864\n",
            "Epoch 6: val_loss did not improve from 1.12391\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8818 - accuracy: 0.6864 - val_loss: 1.3308 - val_accuracy: 0.5351 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.6905\n",
            "Epoch 7: val_loss did not improve from 1.12391\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8707 - accuracy: 0.6905 - val_loss: 1.2413 - val_accuracy: 0.5569 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8677 - accuracy: 0.6927\n",
            "Epoch 8: val_loss did not improve from 1.12391\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8677 - accuracy: 0.6927 - val_loss: 1.1745 - val_accuracy: 0.5741 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8623 - accuracy: 0.6928\n",
            "Epoch 9: val_loss did not improve from 1.12391\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.8623 - accuracy: 0.6928 - val_loss: 1.1630 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8544 - accuracy: 0.6951\n",
            "Epoch 10: val_loss did not improve from 1.12391\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8544 - accuracy: 0.6951 - val_loss: 1.1381 - val_accuracy: 0.5920 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8533 - accuracy: 0.6956\n",
            "Epoch 11: val_loss did not improve from 1.12391\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8533 - accuracy: 0.6956 - val_loss: 1.2026 - val_accuracy: 0.5992 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.6990\n",
            "Epoch 12: val_loss improved from 1.12391 to 1.10988, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 42s 84ms/step - loss: 0.8458 - accuracy: 0.6990 - val_loss: 1.1099 - val_accuracy: 0.6031 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.6979\n",
            "Epoch 13: val_loss did not improve from 1.10988\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8433 - accuracy: 0.6979 - val_loss: 1.1396 - val_accuracy: 0.5998 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8398 - accuracy: 0.6989\n",
            "Epoch 14: val_loss did not improve from 1.10988\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8398 - accuracy: 0.6989 - val_loss: 1.1620 - val_accuracy: 0.5970 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8360 - accuracy: 0.7010\n",
            "Epoch 15: val_loss did not improve from 1.10988\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8360 - accuracy: 0.7010 - val_loss: 1.1350 - val_accuracy: 0.5925 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8275 - accuracy: 0.7044\n",
            "Epoch 16: val_loss did not improve from 1.10988\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8275 - accuracy: 0.7044 - val_loss: 1.1155 - val_accuracy: 0.6042 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8229 - accuracy: 0.7079\n",
            "Epoch 17: val_loss improved from 1.10988 to 1.07623, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 42s 83ms/step - loss: 0.8229 - accuracy: 0.7079 - val_loss: 1.0762 - val_accuracy: 0.6171 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8182 - accuracy: 0.7102\n",
            "Epoch 18: val_loss did not improve from 1.07623\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8182 - accuracy: 0.7102 - val_loss: 1.0968 - val_accuracy: 0.6104 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8141 - accuracy: 0.7111\n",
            "Epoch 19: val_loss did not improve from 1.07623\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8141 - accuracy: 0.7111 - val_loss: 1.1319 - val_accuracy: 0.6014 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8159 - accuracy: 0.7123\n",
            "Epoch 20: val_loss did not improve from 1.07623\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8159 - accuracy: 0.7123 - val_loss: 1.0940 - val_accuracy: 0.6070 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8113 - accuracy: 0.7105\n",
            "Epoch 21: val_loss did not improve from 1.07623\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8113 - accuracy: 0.7105 - val_loss: 1.0983 - val_accuracy: 0.6148 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8003 - accuracy: 0.7151\n",
            "Epoch 22: val_loss did not improve from 1.07623\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8003 - accuracy: 0.7151 - val_loss: 1.1531 - val_accuracy: 0.5831 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7985 - accuracy: 0.7140\n",
            "Epoch 23: val_loss improved from 1.07623 to 1.06870, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 42s 83ms/step - loss: 0.7985 - accuracy: 0.7140 - val_loss: 1.0687 - val_accuracy: 0.6137 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8003 - accuracy: 0.7127\n",
            "Epoch 24: val_loss did not improve from 1.06870\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8003 - accuracy: 0.7127 - val_loss: 1.0741 - val_accuracy: 0.6332 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7877 - accuracy: 0.7177\n",
            "Epoch 25: val_loss improved from 1.06870 to 1.03240, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 45s 89ms/step - loss: 0.7877 - accuracy: 0.7177 - val_loss: 1.0324 - val_accuracy: 0.6433 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7836 - accuracy: 0.7217\n",
            "Epoch 26: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7836 - accuracy: 0.7217 - val_loss: 1.2254 - val_accuracy: 0.5897 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7761 - accuracy: 0.7236\n",
            "Epoch 27: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7761 - accuracy: 0.7236 - val_loss: 1.0841 - val_accuracy: 0.6132 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7787 - accuracy: 0.7231\n",
            "Epoch 28: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7787 - accuracy: 0.7231 - val_loss: 1.0920 - val_accuracy: 0.6020 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7715 - accuracy: 0.7219\n",
            "Epoch 29: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7715 - accuracy: 0.7219 - val_loss: 1.1161 - val_accuracy: 0.6193 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7686 - accuracy: 0.7274\n",
            "Epoch 30: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7686 - accuracy: 0.7274 - val_loss: 1.1851 - val_accuracy: 0.6020 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.8253 - accuracy: 0.7087\n",
            "Epoch 31: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.8253 - accuracy: 0.7087 - val_loss: 1.2526 - val_accuracy: 0.5764 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7836 - accuracy: 0.7221\n",
            "Epoch 32: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7836 - accuracy: 0.7221 - val_loss: 1.0591 - val_accuracy: 0.6321 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7599 - accuracy: 0.7276\n",
            "Epoch 33: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7599 - accuracy: 0.7276 - val_loss: 1.0919 - val_accuracy: 0.6310 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7546 - accuracy: 0.7307\n",
            "Epoch 34: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7546 - accuracy: 0.7307 - val_loss: 1.0423 - val_accuracy: 0.6282 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.7464 - accuracy: 0.7347\n",
            "Epoch 35: val_loss did not improve from 1.03240\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7464 - accuracy: 0.7347 - val_loss: 1.1854 - val_accuracy: 0.5847 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.7637\n",
            "Epoch 36: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.6625 - accuracy: 0.7637 - val_loss: 1.0606 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.7762\n",
            "Epoch 37: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.6313 - accuracy: 0.7762 - val_loss: 1.0546 - val_accuracy: 0.6427 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.7781\n",
            "Epoch 38: val_loss did not improve from 1.03240\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.6270 - accuracy: 0.7781 - val_loss: 1.0752 - val_accuracy: 0.6399 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.7837\n",
            "Epoch 39: val_loss improved from 1.03240 to 1.02983, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 42s 84ms/step - loss: 0.6090 - accuracy: 0.7837 - val_loss: 1.0298 - val_accuracy: 0.6577 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.7831\n",
            "Epoch 40: val_loss did not improve from 1.02983\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.6050 - accuracy: 0.7831 - val_loss: 1.0337 - val_accuracy: 0.6466 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.7856\n",
            "Epoch 41: val_loss did not improve from 1.02983\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5964 - accuracy: 0.7856 - val_loss: 1.0529 - val_accuracy: 0.6538 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5879 - accuracy: 0.7869\n",
            "Epoch 42: val_loss did not improve from 1.02983\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5879 - accuracy: 0.7869 - val_loss: 1.0570 - val_accuracy: 0.6438 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.7884\n",
            "Epoch 43: val_loss did not improve from 1.02983\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5906 - accuracy: 0.7884 - val_loss: 1.0507 - val_accuracy: 0.6488 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.7930\n",
            "Epoch 44: val_loss improved from 1.02983 to 1.02834, saving model to /content/drive/MyDrive/DL Facial Recognition /FacialExpression_weights_resnet.hdf5\n",
            "504/504 [==============================] - 43s 86ms/step - loss: 0.5797 - accuracy: 0.7930 - val_loss: 1.0283 - val_accuracy: 0.6555 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.7963\n",
            "Epoch 45: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5727 - accuracy: 0.7963 - val_loss: 1.0449 - val_accuracy: 0.6438 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.7933\n",
            "Epoch 46: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5736 - accuracy: 0.7933 - val_loss: 1.0669 - val_accuracy: 0.6455 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.7953\n",
            "Epoch 47: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5710 - accuracy: 0.7953 - val_loss: 1.0781 - val_accuracy: 0.6444 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7961\n",
            "Epoch 48: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5660 - accuracy: 0.7961 - val_loss: 1.0965 - val_accuracy: 0.6438 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7969\n",
            "Epoch 49: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5649 - accuracy: 0.7969 - val_loss: 1.0757 - val_accuracy: 0.6349 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.8006\n",
            "Epoch 50: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5593 - accuracy: 0.8006 - val_loss: 1.0504 - val_accuracy: 0.6527 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5598 - accuracy: 0.7966\n",
            "Epoch 51: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5598 - accuracy: 0.7966 - val_loss: 1.0535 - val_accuracy: 0.6577 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.8001\n",
            "Epoch 52: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5567 - accuracy: 0.8001 - val_loss: 1.0461 - val_accuracy: 0.6511 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.7993\n",
            "Epoch 53: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5540 - accuracy: 0.7993 - val_loss: 1.0728 - val_accuracy: 0.6421 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.7995\n",
            "Epoch 54: val_loss did not improve from 1.02834\n",
            "\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5493 - accuracy: 0.7995 - val_loss: 1.0796 - val_accuracy: 0.6460 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.8050\n",
            "Epoch 55: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5386 - accuracy: 0.8050 - val_loss: 1.0659 - val_accuracy: 0.6538 - lr: 1.0000e-05\n",
            "Epoch 56/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.8059\n",
            "Epoch 56: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 37s 74ms/step - loss: 0.5343 - accuracy: 0.8059 - val_loss: 1.0735 - val_accuracy: 0.6516 - lr: 1.0000e-05\n",
            "Epoch 57/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.8078\n",
            "Epoch 57: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5342 - accuracy: 0.8078 - val_loss: 1.0738 - val_accuracy: 0.6544 - lr: 1.0000e-05\n",
            "Epoch 58/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.8086\n",
            "Epoch 58: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5333 - accuracy: 0.8086 - val_loss: 1.0754 - val_accuracy: 0.6483 - lr: 1.0000e-05\n",
            "Epoch 59/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.8104\n",
            "Epoch 59: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5252 - accuracy: 0.8104 - val_loss: 1.0754 - val_accuracy: 0.6483 - lr: 1.0000e-05\n",
            "Epoch 60/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8072\n",
            "Epoch 60: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5299 - accuracy: 0.8072 - val_loss: 1.0797 - val_accuracy: 0.6499 - lr: 1.0000e-05\n",
            "Epoch 61/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.8076\n",
            "Epoch 61: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5346 - accuracy: 0.8076 - val_loss: 1.0741 - val_accuracy: 0.6488 - lr: 1.0000e-05\n",
            "Epoch 62/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.8080\n",
            "Epoch 62: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5319 - accuracy: 0.8080 - val_loss: 1.0782 - val_accuracy: 0.6460 - lr: 1.0000e-05\n",
            "Epoch 63/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.8054\n",
            "Epoch 63: val_loss did not improve from 1.02834\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5359 - accuracy: 0.8054 - val_loss: 1.0697 - val_accuracy: 0.6488 - lr: 1.0000e-05\n",
            "Epoch 64/100\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.8071\n",
            "Epoch 64: val_loss did not improve from 1.02834\n",
            "\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "504/504 [==============================] - 38s 74ms/step - loss: 0.5305 - accuracy: 0.8071 - val_loss: 1.0760 - val_accuracy: 0.6466 - lr: 1.0000e-05\n",
            "Epoch 64: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator, steps_per_epoch=len(X_train)//batch_size, epochs=total_epochs, validation_data=(X_val, y_val), validation_steps=len(X_val)//batch_size, callbacks=[checkpointer, earlystopping, reduce_lr])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQG5lM6qEQ3q",
        "outputId": "edb6983a-51fb-445c-d0f3-225e516cc70f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 1s 11ms/step - loss: 1.0631 - accuracy: 0.6485\n",
            "Test Accuracy: 0.6484679579734802\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test Accuracy: {}'.format(score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "nZEJehHPEJ9M",
        "outputId": "36250922-2d18-4a57-db42-142bf2dd8258"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting loss curves\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwzuZObvEKy3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}